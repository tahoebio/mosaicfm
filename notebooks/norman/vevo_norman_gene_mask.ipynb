{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abafa220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/ahz/poetry_env/lib/python3.9/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "#import scvi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "#import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, eval_scib_metrics, load_pretrained\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716574d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewhz-zhang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/ahz/mosaicfm/wandb/run-20250226_002359-39t1s67u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewhz-zhang/scGPT/runs/39t1s67u\" target=\"_blank\">lemon-night-126</a></strong> to <a href=\"https://wandb.ai/andrewhz-zhang/scGPT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'dataset_name': 'norman', 'do_train': True, 'load_model': '/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model', 'model_name': 'best_model.pt', 'GEPC': True, 'ecs_thres': 0.8, 'dab_weight': 1.0, 'mask_ratio': 0.4, 'epochs': 15, 'n_bins': 51, 'lr': 0.0001, 'batch_size': 64, 'layer_size': 128, 'nlayers': 4, 'nhead': 4, 'dropout': 0.2, 'schedule_ratio': 0.9, 'save_eval_interval': 5, 'log_interval': 100, 'fast_transformer': True, 'pre_norm': False, 'amp': True}\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=42,\n",
    "    dataset_name=\"norman\", # Dataset name\n",
    "    do_train=True, # Flag to indicate whether to do update model parameters during training\n",
    "    load_model=\"/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model\",\n",
    "    model_name=\"best_model.pt\",\n",
    "    GEPC=True,  # Gene expression modelling for cell objective\n",
    "    ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0, # DAR objective weight for batch correction\n",
    "    mask_ratio=0.4, # Default mask ratio\n",
    "    epochs=15, # Default number of epochs for fine-tuning\n",
    "    n_bins=51, # Default number of bins for value binning in data pre-processing\n",
    "    lr=1e-4, # Default learning rate for fine-tuning\n",
    "    batch_size=64, # Default batch size for fine-tuning\n",
    "    layer_size=128,\n",
    "    nlayers=4,\n",
    "    nhead=4, # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2, # Default dropout rate during model fine-tuning\n",
    "    schedule_ratio=0.9,  # Default rate for learning rate decay\n",
    "    save_eval_interval=5, # Default model evaluation interval\n",
    "    log_interval=100, # Default log interval\n",
    "    fast_transformer=True, # Default setting\n",
    "    pre_norm=False, # Default setting\n",
    "    amp=True,  # # Default setting: Automatic Mixed Precision\n",
    ")\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40811ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to /scratch/ssd004/scratch/ahz/perturb/dev_norman-Feb26-00-24\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# settings for input and preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = config.n_bins\n",
    "\n",
    "n_hvg = 1200  # number of highly variable genes\n",
    "max_seq_len = n_hvg + 1\n",
    "per_seq_batch_sample = True\n",
    "DSBN = False  # Domain-spec batchnorm\n",
    "explicit_zero_prob = True  # whether explicit bernoulli for zeros\n",
    "\n",
    "dataset_name = config.dataset_name\n",
    "save_dir = Path(f\"/scratch/ssd004/scratch/ahz/perturb/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a65666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21128b5",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset\n",
    "\n",
    "####  ✅ Note\n",
    "Perturbation datasets can be found in this path: `/scratch/ssd004/scratch/chloexq/perturb_analysis/{dataset_name}` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8699653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/scratch/ssd004/scratch/chloexq/perturb_analysis\")\n",
    "adata = sc.read(data_dir / \"norman/perturb_processed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db641f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 91205 × 5045\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name'\n",
       "    var: 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b57b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index = pd.Index(adata.var[\"gene_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338c15de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AHR+FEV', 'AHR+KLF1', 'AHR+ctrl', 'ARID1A+ctrl', 'ARRDC3+ctrl',\n",
       "       'ATL1+ctrl', 'BAK1+ctrl', 'BCL2L11+BAK1', 'BCL2L11+TGFBR2',\n",
       "       'BCL2L11+ctrl', 'BCORL1+ctrl', 'BPGM+SAMD1', 'BPGM+ZBTB1',\n",
       "       'BPGM+ctrl', 'C19orf26+ctrl', 'C3orf72+FOXL2', 'C3orf72+ctrl',\n",
       "       'CBFA2T3+ctrl', 'CBL+CNN1', 'CBL+PTPN12', 'CBL+PTPN9',\n",
       "       'CBL+TGFBR2', 'CBL+UBASH3A', 'CBL+UBASH3B', 'CBL+ctrl',\n",
       "       'CDKN1A+ctrl', 'CDKN1B+CDKN1A', 'CDKN1B+ctrl', 'CDKN1C+CDKN1A',\n",
       "       'CDKN1C+CDKN1B', 'CDKN1C+ctrl', 'CEBPA+ctrl', 'CEBPB+CEBPA',\n",
       "       'CEBPB+MAPK1', 'CEBPB+OSR2', 'CEBPB+PTPN12', 'CEBPB+ctrl',\n",
       "       'CEBPE+CEBPA', 'CEBPE+CEBPB', 'CEBPE+CNN1', 'CEBPE+KLF1',\n",
       "       'CEBPE+PTPN12', 'CEBPE+RUNX1T1', 'CEBPE+SPI1', 'CEBPE+ctrl',\n",
       "       'CELF2+ctrl', 'CITED1+ctrl', 'CKS1B+ctrl', 'CLDN6+ctrl',\n",
       "       'CNN1+MAPK1', 'CNN1+UBASH3A', 'CNN1+ctrl', 'CNNM4+ctrl',\n",
       "       'COL1A1+ctrl', 'COL2A1+ctrl', 'CSRNP1+ctrl', 'DLX2+ctrl',\n",
       "       'DUSP9+ETS2', 'DUSP9+IGDCC3', 'DUSP9+KLF1', 'DUSP9+MAPK1',\n",
       "       'DUSP9+PRTG', 'DUSP9+SNAI1', 'DUSP9+ctrl', 'EGR1+ctrl',\n",
       "       'ELMSAN1+ctrl', 'ETS2+CEBPE', 'ETS2+CNN1', 'ETS2+IGDCC3',\n",
       "       'ETS2+IKZF3', 'ETS2+MAP7D1', 'ETS2+MAPK1', 'ETS2+PRTG',\n",
       "       'ETS2+ctrl', 'FEV+CBFA2T3', 'FEV+ISL2', 'FEV+MAP7D1', 'FEV+ctrl',\n",
       "       'FOSB+CEBPB', 'FOSB+CEBPE', 'FOSB+IKZF3', 'FOSB+OSR2',\n",
       "       'FOSB+PTPN12', 'FOSB+UBASH3B', 'FOSB+ctrl', 'FOXA1+FOXF1',\n",
       "       'FOXA1+FOXL2', 'FOXA1+HOXB9', 'FOXA1+ctrl', 'FOXA3+FOXA1',\n",
       "       'FOXA3+FOXF1', 'FOXA3+FOXL2', 'FOXA3+HOXB9', 'FOXA3+ctrl',\n",
       "       'FOXF1+FOXL2', 'FOXF1+HOXB9', 'FOXF1+ctrl', 'FOXL2+HOXB9',\n",
       "       'FOXL2+MEIS1', 'FOXL2+ctrl', 'FOXO4+ctrl', 'GLB1L2+ctrl',\n",
       "       'HES7+ctrl', 'HK2+ctrl', 'HNF4A+ctrl', 'HOXA13+ctrl', 'HOXB9+ctrl',\n",
       "       'HOXC13+ctrl', 'IER5L+ctrl', 'IGDCC3+MAPK1', 'IGDCC3+PRTG',\n",
       "       'IGDCC3+ZBTB25', 'IGDCC3+ctrl', 'IKZF3+ctrl', 'IRF1+SET',\n",
       "       'IRF1+ctrl', 'ISL2+ctrl', 'JUN+CEBPA', 'JUN+CEBPB', 'JUN+ctrl',\n",
       "       'KIAA1804+ctrl', 'KIF18B+KIF2C', 'KIF18B+ctrl', 'KIF2C+ctrl',\n",
       "       'KLF1+BAK1', 'KLF1+CEBPA', 'KLF1+CLDN6', 'KLF1+COL2A1',\n",
       "       'KLF1+FOXA1', 'KLF1+MAP2K6', 'KLF1+TGFBR2', 'KLF1+ctrl',\n",
       "       'KMT2A+ctrl', 'LHX1+ELMSAN1', 'LHX1+ctrl', 'LYL1+CEBPB',\n",
       "       'LYL1+IER5L', 'LYL1+ctrl', 'MAML2+ctrl', 'MAP2K3+ELMSAN1',\n",
       "       'MAP2K3+IKZF3', 'MAP2K3+MAP2K6', 'MAP2K3+SLC38A2', 'MAP2K3+ctrl',\n",
       "       'MAP2K6+ELMSAN1', 'MAP2K6+IKZF3', 'MAP2K6+SPI1', 'MAP2K6+ctrl',\n",
       "       'MAP4K3+ctrl', 'MAP4K5+ctrl', 'MAP7D1+ctrl', 'MAPK1+IKZF3',\n",
       "       'MAPK1+PRTG', 'MAPK1+TGFBR2', 'MAPK1+ctrl', 'MEIS1+ctrl',\n",
       "       'MIDN+ctrl', 'NCL+ctrl', 'NIT1+ctrl', 'OSR2+ctrl', 'PLK4+STIL',\n",
       "       'PLK4+ctrl', 'POU3F2+CBFA2T3', 'POU3F2+FOXL2', 'POU3F2+ctrl',\n",
       "       'PRDM1+CBFA2T3', 'PRDM1+ctrl', 'PRTG+ctrl', 'PTPN1+ctrl',\n",
       "       'PTPN12+OSR2', 'PTPN12+PTPN9', 'PTPN12+SNAI1', 'PTPN12+UBASH3A',\n",
       "       'PTPN12+ZBTB25', 'PTPN12+ctrl', 'PTPN13+ctrl', 'PTPN9+ctrl',\n",
       "       'RHOXF2BB+SET', 'RHOXF2BB+ZBTB25', 'RHOXF2BB+ctrl', 'RREB1+ctrl',\n",
       "       'RUNX1T1+ctrl', 'S1PR2+ctrl', 'SAMD1+PTPN12', 'SAMD1+TGFBR2',\n",
       "       'SAMD1+UBASH3B', 'SAMD1+ZBTB1', 'SAMD1+ctrl', 'SET+CEBPE',\n",
       "       'SET+KLF1', 'SET+ctrl', 'SGK1+S1PR2', 'SGK1+TBX2', 'SGK1+TBX3',\n",
       "       'SGK1+ctrl', 'SLC4A1+ctrl', 'SLC6A9+ctrl', 'SNAI1+DLX2',\n",
       "       'SNAI1+UBASH3B', 'SNAI1+ctrl', 'SPI1+ctrl', 'STIL+ctrl',\n",
       "       'TBX2+ctrl', 'TBX3+TBX2', 'TBX3+ctrl', 'TGFBR2+C19orf26',\n",
       "       'TGFBR2+ETS2', 'TGFBR2+IGDCC3', 'TGFBR2+PRTG', 'TGFBR2+ctrl',\n",
       "       'TMSB4X+BAK1', 'TMSB4X+ctrl', 'TP73+ctrl', 'TSC22D1+ctrl',\n",
       "       'UBASH3A+ctrl', 'UBASH3B+CNN1', 'UBASH3B+OSR2', 'UBASH3B+PTPN12',\n",
       "       'UBASH3B+PTPN9', 'UBASH3B+UBASH3A', 'UBASH3B+ZBTB25',\n",
       "       'UBASH3B+ctrl', 'ZBTB1+ctrl', 'ZBTB10+DLX2', 'ZBTB10+ELMSAN1',\n",
       "       'ZBTB10+PTPN12', 'ZBTB10+SNAI1', 'ZBTB10+ctrl', 'ZBTB25+ctrl',\n",
       "       'ZC3HAV1+CEBPA', 'ZC3HAV1+CEBPE', 'ZC3HAV1+HOXC13', 'ZC3HAV1+ctrl',\n",
       "       'ZNF318+FOXL2', 'ZNF318+ctrl', 'ctrl', 'ctrl+BAK1',\n",
       "       'ctrl+C19orf26', 'ctrl+CBFA2T3', 'ctrl+CDKN1A', 'ctrl+CDKN1B',\n",
       "       'ctrl+CEBPA', 'ctrl+CEBPB', 'ctrl+CEBPE', 'ctrl+CLDN6',\n",
       "       'ctrl+CNN1', 'ctrl+COL2A1', 'ctrl+DLX2', 'ctrl+ELMSAN1',\n",
       "       'ctrl+ETS2', 'ctrl+FEV', 'ctrl+FOXA1', 'ctrl+FOXF1', 'ctrl+FOXL2',\n",
       "       'ctrl+HOXB9', 'ctrl+HOXC13', 'ctrl+IER5L', 'ctrl+IGDCC3',\n",
       "       'ctrl+IKZF3', 'ctrl+ISL2', 'ctrl+KIF2C', 'ctrl+KLF1',\n",
       "       'ctrl+MAP2K6', 'ctrl+MAP7D1', 'ctrl+MAPK1', 'ctrl+MEIS1',\n",
       "       'ctrl+OSR2', 'ctrl+PRTG', 'ctrl+PTPN12', 'ctrl+PTPN9',\n",
       "       'ctrl+RUNX1T1', 'ctrl+SAMD1', 'ctrl+SET', 'ctrl+SLC38A2',\n",
       "       'ctrl+SNAI1', 'ctrl+SPI1', 'ctrl+STIL', 'ctrl+TBX2', 'ctrl+TBX3',\n",
       "       'ctrl+TGFBR2', 'ctrl+UBASH3A', 'ctrl+UBASH3B', 'ctrl+ZBTB1',\n",
       "       'ctrl+ZBTB25'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(adata.obs.condition.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544bacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(adata.obs.condition.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1338d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AHR+ctrl', 'ARID1A+ctrl', 'ARRDC3+ctrl', 'ATL1+ctrl', 'BAK1+ctrl', 'BCL2L11+ctrl', 'BCORL1+ctrl', 'BPGM+ctrl', 'C19orf26+ctrl', 'C3orf72+ctrl', 'CBFA2T3+ctrl', 'CBL+ctrl', 'CDKN1A+ctrl', 'CDKN1B+ctrl', 'CDKN1C+ctrl', 'CEBPA+ctrl', 'CEBPB+ctrl', 'CEBPE+ctrl', 'CELF2+ctrl', 'CITED1+ctrl', 'CKS1B+ctrl', 'CLDN6+ctrl', 'CNN1+ctrl', 'CNNM4+ctrl', 'COL1A1+ctrl', 'COL2A1+ctrl', 'CSRNP1+ctrl', 'DLX2+ctrl', 'DUSP9+ctrl', 'EGR1+ctrl', 'ELMSAN1+ctrl', 'ETS2+ctrl', 'FEV+ctrl', 'FOSB+ctrl', 'FOXA1+ctrl', 'FOXA3+ctrl', 'FOXF1+ctrl', 'FOXL2+ctrl', 'FOXO4+ctrl', 'GLB1L2+ctrl', 'HES7+ctrl', 'HK2+ctrl', 'HNF4A+ctrl', 'HOXA13+ctrl', 'HOXB9+ctrl', 'HOXC13+ctrl', 'IER5L+ctrl', 'IGDCC3+ctrl', 'IKZF3+ctrl', 'IRF1+ctrl', 'ISL2+ctrl', 'JUN+ctrl', 'KIAA1804+ctrl', 'KIF18B+ctrl', 'KIF2C+ctrl', 'KLF1+ctrl', 'KMT2A+ctrl', 'LHX1+ctrl', 'LYL1+ctrl', 'MAML2+ctrl', 'MAP2K3+ctrl', 'MAP2K6+ctrl', 'MAP4K3+ctrl', 'MAP4K5+ctrl', 'MAP7D1+ctrl', 'MAPK1+ctrl', 'MEIS1+ctrl', 'MIDN+ctrl', 'NCL+ctrl', 'NIT1+ctrl', 'OSR2+ctrl', 'PLK4+ctrl', 'POU3F2+ctrl', 'PRDM1+ctrl', 'PRTG+ctrl', 'PTPN1+ctrl', 'PTPN12+ctrl', 'PTPN13+ctrl', 'PTPN9+ctrl', 'RHOXF2BB+ctrl', 'RREB1+ctrl', 'RUNX1T1+ctrl', 'S1PR2+ctrl', 'SAMD1+ctrl', 'SET+ctrl', 'SGK1+ctrl', 'SLC4A1+ctrl', 'SLC6A9+ctrl', 'SNAI1+ctrl', 'SPI1+ctrl', 'STIL+ctrl', 'TBX2+ctrl', 'TBX3+ctrl', 'TGFBR2+ctrl', 'TMSB4X+ctrl', 'TP73+ctrl', 'TSC22D1+ctrl', 'UBASH3A+ctrl', 'UBASH3B+ctrl', 'ZBTB1+ctrl', 'ZBTB10+ctrl', 'ZBTB25+ctrl', 'ZC3HAV1+ctrl', 'ZNF318+ctrl', 'ctrl', 'ctrl+BAK1', 'ctrl+C19orf26', 'ctrl+CBFA2T3', 'ctrl+CDKN1A', 'ctrl+CDKN1B', 'ctrl+CEBPA', 'ctrl+CEBPB', 'ctrl+CEBPE', 'ctrl+CLDN6', 'ctrl+CNN1', 'ctrl+COL2A1', 'ctrl+DLX2', 'ctrl+ELMSAN1', 'ctrl+ETS2', 'ctrl+FEV', 'ctrl+FOXA1', 'ctrl+FOXF1', 'ctrl+FOXL2', 'ctrl+HOXB9', 'ctrl+HOXC13', 'ctrl+IER5L', 'ctrl+IGDCC3', 'ctrl+IKZF3', 'ctrl+ISL2', 'ctrl+KIF2C', 'ctrl+KLF1', 'ctrl+MAP2K6', 'ctrl+MAP7D1', 'ctrl+MAPK1', 'ctrl+MEIS1', 'ctrl+OSR2', 'ctrl+PRTG', 'ctrl+PTPN12', 'ctrl+PTPN9', 'ctrl+RUNX1T1', 'ctrl+SAMD1', 'ctrl+SET', 'ctrl+SLC38A2', 'ctrl+SNAI1', 'ctrl+SPI1', 'ctrl+STIL', 'ctrl+TBX2', 'ctrl+TBX3', 'ctrl+TGFBR2', 'ctrl+UBASH3A', 'ctrl+UBASH3B', 'ctrl+ZBTB1', 'ctrl+ZBTB25'] 153\n"
     ]
    }
   ],
   "source": [
    "single_gene_filter = [i for i in np.unique(adata.obs.condition.values) if not ('+' in i and 'ctrl' not in i)]\n",
    "print(single_gene_filter, len(single_gene_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af595f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs.condition.isin(single_gene_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7601f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 55760 × 5045\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name'\n",
       "    var: 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a8b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update condition names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e80ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_batch_col = \"control\"\n",
    "adata.obs[\"celltype\"] = adata.obs[\"condition\"].astype(\"category\")\n",
    "adata.obs[\"str_batch\"] = adata.obs[\"control\"].astype(str)\n",
    "data_is_raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e74c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 4547/5045 genes in vocabulary of size 60697.\n",
      "Resume model from /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/best_model.pt, the model args will be overriden by the config /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/args.json.\n"
     ]
    }
   ],
   "source": [
    "if config.load_model is not None:\n",
    "    model_dir = Path(config.load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / config.model_name\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    print(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n",
    "    \n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    print(\n",
    "        f\"Resume model from {model_file}, the model args will be overriden by the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "else:\n",
    "    embsize = config.layer_size \n",
    "    nhead = config.nhead\n",
    "    nlayers = config.nlayers  \n",
    "    d_hid = config.layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e69a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names_set = [i + '+ctrl' for i in adata.var.gene_name.values]\n",
    "gene_names_set = gene_names_set + ['ctrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933d35f",
   "metadata": {},
   "source": [
    "####  ✅ Note\n",
    "This experiment is computationally expensive, so we select 1000 cells per perturbation condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1185ae66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AHR+ctrl</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARID1A+ctrl</th>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARRDC3+ctrl</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL1+ctrl</th>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAK1+ctrl</th>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB1+ctrl</th>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB10+ctrl</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB25+ctrl</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZC3HAV1+ctrl</th>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF318+ctrl</th>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cell_type  dose_val  control  condition_name  celltype  \\\n",
       "condition                                                              \n",
       "AHR+ctrl            479       479      479             479       479   \n",
       "ARID1A+ctrl         182       182      182             182       182   \n",
       "ARRDC3+ctrl         405       405      405             405       405   \n",
       "ATL1+ctrl           305       305      305             305       305   \n",
       "BAK1+ctrl           534       534      534             534       534   \n",
       "...                 ...       ...      ...             ...       ...   \n",
       "ZBTB1+ctrl          315       315      315             315       315   \n",
       "ZBTB10+ctrl         145       145      145             145       145   \n",
       "ZBTB25+ctrl         343       343      343             343       343   \n",
       "ZC3HAV1+ctrl        436       436      436             436       436   \n",
       "ZNF318+ctrl         541       541      541             541       541   \n",
       "\n",
       "              str_batch  \n",
       "condition                \n",
       "AHR+ctrl            479  \n",
       "ARID1A+ctrl         182  \n",
       "ARRDC3+ctrl         405  \n",
       "ATL1+ctrl           305  \n",
       "BAK1+ctrl           534  \n",
       "...                 ...  \n",
       "ZBTB1+ctrl          315  \n",
       "ZBTB10+ctrl         145  \n",
       "ZBTB25+ctrl         343  \n",
       "ZC3HAV1+ctrl        436  \n",
       "ZNF318+ctrl         541  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap all conditions to 1000 cells\n",
    "sampled_df = (\n",
    "    adata.obs[adata.obs['condition'].isin(gene_names_set)]\n",
    "    .groupby('condition', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), 1000), random_state=42))\n",
    ")\n",
    "adata = adata[sampled_df.index].copy()\n",
    "adata.obs.groupby('condition').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f2e8155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cell_type  dose_val  control  condition_name  celltype  str_batch\n",
       "condition                                                                   \n",
       "ctrl          1000.0    1000.0   1000.0          1000.0    1000.0     1000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 conditions are capped, including ctrl\n",
    "condition_counts = adata.obs.groupby('condition').count()\n",
    "condition_counts[condition_counts == 1000].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "926217f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = set(adata.obs.condition.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20cf69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names.remove('ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9982e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene = [i.split('+')[0] for i in list(condition_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da55a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72c6da",
   "metadata": {},
   "source": [
    "####  ✅ Note\n",
    "HVGs selection will filter out some perturbed genes. We manually add them back in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5874e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n"
     ]
    }
   ],
   "source": [
    "# Do filtering\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=3,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    #binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    #result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4100ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    layer=None,\n",
    "    n_top_genes=1200,\n",
    "    flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    subset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f73f0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_counter = 0\n",
    "for g in condition_names_gene:\n",
    "    if not adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'].values[0]:\n",
    "        adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'] = True\n",
    "        add_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0196dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually add conditions: 67, 0.6767676767676768\n"
     ]
    }
   ],
   "source": [
    "print('Manually add conditions: {}, {}'.format(add_counter, add_counter/len(condition_names_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a644f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "# This step for binning\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=0,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab55acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 33059 × 1267\n",
      "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch'\n",
      "    var: 'gene_name', 'id_in_vocab', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n",
      "    obsm: 'bin_edges'\n",
      "    layers: 'counts', 'X_binned'\n"
     ]
    }
   ],
   "source": [
    "adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526d709",
   "metadata": {},
   "source": [
    "#### 🔵 Optional\n",
    "Create another randomly shuffled list of `condition_names_gene_match` as control, if running the control experiment. \n",
    "Note that there are many ways to construct the control list, either from perturbation targets or random from all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c8e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of randomly shuffle perturbation targets\n",
    "import random\n",
    "random.seed(42)\n",
    "condition_names_gene_match = condition_names_gene.copy()\n",
    "random.shuffle(condition_names_gene_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f5baedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of using non-targets\n",
    "# This is the most recent version\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "non_targets = list(set(genes).difference(set(condition_names_gene)))\n",
    "non_targets.sort()\n",
    "random.seed(42)\n",
    "random.shuffle(non_targets)\n",
    "non_targets\n",
    "condition_names_gene_match = non_targets[:len(condition_names_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b2320a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AHR', 'ARID1A', 'ARRDC3', 'ATL1', 'BAK1', 'BCL2L11', 'BCORL1', 'BPGM', 'CBFA2T3', 'CBL', 'CDKN1A', 'CDKN1B', 'CDKN1C', 'CEBPA', 'CEBPB', 'CEBPE', 'CELF2', 'CITED1', 'CKS1B', 'CLDN6', 'CNN1', 'CNNM4', 'COL1A1', 'COL2A1', 'CSRNP1', 'DLX2', 'DUSP9', 'EGR1', 'ETS2', 'FEV', 'FOSB', 'FOXA1', 'FOXA3', 'FOXF1', 'FOXL2', 'FOXO4', 'GLB1L2', 'HES7', 'HK2', 'HNF4A', 'HOXA13', 'HOXB9', 'HOXC13', 'IER5L', 'IGDCC3', 'IKZF3', 'IRF1', 'ISL2', 'JUN', 'KIF18B', 'KIF2C', 'KLF1', 'KMT2A', 'LHX1', 'LYL1', 'MAML2', 'MAP2K3', 'MAP2K6', 'MAP4K3', 'MAP4K5', 'MAP7D1', 'MAPK1', 'MEIS1', 'MIDN', 'NCL', 'NIT1', 'OSR2', 'PLK4', 'POU3F2', 'PRDM1', 'PRTG', 'PTPN1', 'PTPN12', 'PTPN13', 'PTPN9', 'RREB1', 'RUNX1T1', 'S1PR2', 'SAMD1', 'SET', 'SGK1', 'SLC4A1', 'SLC6A9', 'SNAI1', 'SPI1', 'STIL', 'TBX2', 'TBX3', 'TGFBR2', 'TMSB4X', 'TP73', 'TSC22D1', 'UBASH3A', 'UBASH3B', 'ZBTB1', 'ZBTB10', 'ZBTB25', 'ZC3HAV1', 'ZNF318']\n"
     ]
    }
   ],
   "source": [
    "print(condition_names_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91295c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RASSF4', 'FUT7', 'IL22RA2', 'IP6K3', 'MANF', 'TIMP1', 'MLC1', 'ATF4', 'OR51E1', 'CTD-2623N2.5', 'OS9', 'CYSLTR2', 'ST3GAL6', 'LINC00895', 'HEATR9', 'ANXA2R', 'PMEPA1', 'RP11-46D6.1', 'PDE4DIP', 'RP11-404F10.2', 'APOBEC3D', 'MAOB', 'RP11-90K6.1', 'CD244', 'SVEP1', 'MEIS3', 'GHRL', 'RP11-212I21.4', 'IL6ST', 'ABCA1', 'SLC2A1-AS1', 'CTSO', 'RP11-306G20.1', 'TMEM154', 'PCAT5', 'RP11-443B7.2', 'PCDH9', 'TUBB3', 'SMYD3', 'TRAC', 'PARVG', 'NUTM2G', 'ERP27', 'GDF15', 'RP11-727F15.9', 'RP11-887P2.5', 'HBG2', 'RP5-1086K13.1', 'IRF2BP2', 'PDZK1IP1', 'TEX13D', 'RP11-498P14.5', 'PLAC8', 'C20orf202', 'BTG1', 'GPC1', 'REN', 'HBA2', 'ALDH3B1', 'AC002463.3', 'IL3RA', 'CABP4', 'ICOSLG', 'TXNIP', 'TNFRSF14', 'RP1-286D6.5', 'RP11-1152H14.1', 'EVI2B', 'PPP3CA', 'HBG1', 'PRSS57', 'CD48', 'RNF213', 'EPX', 'CD2', 'TMEM150C', 'FAM166B', 'PNOC', 'IL20', 'TCP11L2', 'CLEC4D', 'AC005616.2', 'SVOPL', 'RAP2C-AS1', 'OPRL1', 'ADIRF', 'PHLDA1', 'ARMCX3', 'FAM234A', 'OSBPL10', 'VWA7', 'ID2-AS1', 'ADRB2', 'ACE', 'ATP10D', 'SP6', 'SMOX', 'MS4A3', 'SYT4']\n"
     ]
    }
   ],
   "source": [
    "print(condition_names_gene_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8a4f5",
   "metadata": {},
   "source": [
    "## Prepare model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ebbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = adata.shape[1] + 1\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3663c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)\n",
    "adata.obs['batch_id'] = adata.obs['condition'].copy()\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "input_layer_key = \"X_binned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5753701",
   "metadata": {},
   "source": [
    "## Load the pre-trained scGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e346fb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    dropout=config.dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=config.GEPC,\n",
    "    do_dab=False,\n",
    "    use_batch_labels=False,\n",
    "    num_batch_labels=num_batch_types,\n",
    "    domain_spec_batchnorm=DSBN,\n",
    "    n_input_bins=n_input_bins,\n",
    "    ecs_threshold=config.ecs_thres,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=config.fast_transformer,\n",
    "    use_generative_training=True,\n",
    "    pre_norm=config.pre_norm,\n",
    ")\n",
    "if config.load_model is not None:\n",
    "    load_pretrained(model, torch.load(model_file), verbose=False)\n",
    "\n",
    "model.to(device)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd1c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "adata_t = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca655eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = (\n",
    "    adata_t.layers[input_layer_key].A\n",
    "    if issparse(adata_t.layers[input_layer_key])\n",
    "    else adata_t.layers[input_layer_key]\n",
    ")\n",
    "celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "batch_ids = np.array(batch_ids)\n",
    "\n",
    "tokenized_all = tokenize_and_pad_batch(\n",
    "    all_counts,\n",
    "    gene_ids,\n",
    "    max_len=max_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=True,\n",
    ")\n",
    "all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900efa46",
   "metadata": {},
   "source": [
    "##  Get gene embeddings (with Value Masking), Calculate Cosine Distance & Rank, and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6647b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cell(tokenized_all, key, k, select_gene_id):\n",
    "    cell_k = tokenized_all[key][k]\n",
    "    # Repeat \n",
    "    cell_k_expand = cell_k.repeat(n_genes).view(n_genes, n_genes)\n",
    "    new_column = torch.full((n_genes, 1), vocab([pad_token])[0])\n",
    "    cell_k_expand = torch.cat((cell_k_expand, new_column), dim=1)\n",
    "    mask = torch.eye(n_genes).bool()\n",
    "    new_column_mask = torch.full((n_genes, 1), False)\n",
    "    mask = torch.cat((mask, new_column_mask), dim=1)\n",
    "    mask[:, select_gene_id] = True\n",
    "    mask[select_gene_id, n_genes] = True\n",
    "    mask_select_expand = cell_k_expand[mask]\n",
    "    select_ids_gen = mask_select_expand.view(n_genes, 2)\n",
    "    select_ids_pcpt = cell_k_expand[~mask].view(n_genes, n_genes-1)\n",
    "    return select_ids_gen, select_ids_pcpt\n",
    "\n",
    "from tqdm import tqdm\n",
    "def collate_cell_by_key(tokenized_all, key, select_gene_id):\n",
    "    print(key)\n",
    "    select_ids_gen_list = []\n",
    "    select_ids_pcpt_list = []\n",
    "    for k in tqdm(range(n_cells)):\n",
    "        select_ids_gen, select_ids_pcpt = expand_cell(tokenized_all, key, k, select_gene_id)\n",
    "        select_ids_gen_list.append(select_ids_gen)\n",
    "        select_ids_pcpt_list.append(select_ids_pcpt)\n",
    "    select_ids_gen = torch.cat(select_ids_gen_list, dim=0)\n",
    "    select_ids_pcpt = torch.cat(select_ids_pcpt_list, dim=0)\n",
    "    print(select_ids_gen.shape, select_ids_pcpt.shape)\n",
    "    return select_ids_gen, select_ids_pcpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58607d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0b7c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_barcode\n",
      "GCTGCGACAAACTGTC-2    AHR+ctrl\n",
      "GCGCAACTCAGGTAAA-6    AHR+ctrl\n",
      "TGCGTGGTCTCGATGA-1    AHR+ctrl\n",
      "CGATGTATCTGGCGAC-1    AHR+ctrl\n",
      "GCGAGAACAGATGGCA-8    AHR+ctrl\n",
      "                        ...   \n",
      "TATCAGGGTAGCTGCC-6        ctrl\n",
      "AGTCTTTTCTCTTATG-4        ctrl\n",
      "ACGAGGAAGGCAGGTT-3        ctrl\n",
      "GACTGCGTCCTCCTAG-8        ctrl\n",
      "CAACTAGGTAGCGTCC-4        ctrl\n",
      "Name: condition, Length: 1479, dtype: category\n",
      "Categories (2, object): ['AHR+ctrl', 'ctrl']\n",
      "439\n",
      "torch.Size([1479, 1268]) torch.Size([1479, 1268])\n",
      "genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1479/1479 [00:07<00:00, 200.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1875372, 2]) torch.Size([1875372, 1267])\n",
      "values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1479/1479 [00:06<00:00, 218.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1875372, 2]) torch.Size([1875372, 1267])\n",
      "{'genes_pcpt': tensor([[24904, 30607, 21504,  ..., 12288, 12289, 60694],\n",
      "        [60695, 30607, 21504,  ..., 12288, 12289, 60694],\n",
      "        [60695, 24904, 21504,  ..., 12288, 12289, 60694],\n",
      "        ...,\n",
      "        [60695, 24904, 30607,  ..., 12288, 12289, 60694],\n",
      "        [60695, 24904, 30607,  ..., 11394, 12289, 60694],\n",
      "        [60695, 24904, 30607,  ..., 11394, 12288, 60694]]), 'genes_gen': tensor([[60695,  1743],\n",
      "        [24904,  1743],\n",
      "        [30607,  1743],\n",
      "        ...,\n",
      "        [ 1743, 11394],\n",
      "        [ 1743, 12288],\n",
      "        [ 1743, 12289]]), 'values_pcpt': tensor([[    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        ...,\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████▍                                                                                                   | 1039/3663 [34:23<1:26:52,  1.99s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "select_gene_list = condition_names_gene\n",
    "\n",
    "for select_gene in select_gene_list:\n",
    "    adata_t = adata[adata.obs['condition'].isin([select_gene+'+ctrl', 'ctrl'])].copy()\n",
    "    print(adata_t.obs['condition'])\n",
    "    select_gene_id = genes.index(select_gene)+1\n",
    "    print(select_gene_id)\n",
    "    all_counts = (\n",
    "        adata_t.layers[input_layer_key].A\n",
    "        if issparse(adata_t.layers[input_layer_key])\n",
    "        else adata_t.layers[input_layer_key]\n",
    "    )\n",
    "    celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "    batch_ids = np.array(batch_ids)\n",
    "\n",
    "    tokenized_all = tokenize_and_pad_batch(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=True,\n",
    "    )\n",
    "    all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "    src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "    print(tokenized_all['genes'].shape, tokenized_all['values'].shape)\n",
    "    n_cells = tokenized_all['genes'].shape[0]\n",
    "    n_genes = tokenized_all['genes'].shape[1]\n",
    "    \n",
    "    collate_genes_gen, collate_genes_pcpt = collate_cell_by_key(tokenized_all, 'genes', select_gene_id)\n",
    "    _, collate_values_pcpt = collate_cell_by_key(tokenized_all, 'values', select_gene_id)\n",
    "    \n",
    "    tokenized_all_expand = {'genes_pcpt': collate_genes_pcpt, 'genes_gen': collate_genes_gen, 'values_pcpt': collate_values_pcpt}\n",
    "    print(tokenized_all_expand)\n",
    "    query_id = tokenized_all['genes'][0].repeat(n_cells)\n",
    "    \n",
    "    cell_counter = torch.arange(0, n_cells)\n",
    "    cell_counter = cell_counter.repeat(n_genes).view(n_genes, n_cells).t().flatten()\n",
    "    gene_counter = torch.arange(0, n_genes).repeat(n_cells)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        TensorDataset(tokenized_all_expand['genes_pcpt'], \n",
    "                      tokenized_all_expand['genes_gen'], \n",
    "                      tokenized_all_expand['values_pcpt'],\n",
    "                      query_id,\n",
    "                      cell_counter,\n",
    "                      gene_counter,\n",
    "                     ), \n",
    "        batch_size=512, \n",
    "        shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    gene_embeddings = np.zeros((n_cells, n_genes, 512))\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=config.amp):\n",
    "        for batch_idx, batch_data in enumerate(tqdm(dataloader)):\n",
    "            pcpt_genes = batch_data[0].to(device)\n",
    "            gen_genes = batch_data[1].to(device)\n",
    "            pcpt_values = batch_data[2].to(device)\n",
    "            query_id_select = batch_data[3].to(device)\n",
    "            cell_counter_batch = batch_data[4].to(device)\n",
    "            gene_counter_batch = batch_data[5].to(device)\n",
    "            pcpt_key_padding_mask = pcpt_genes.eq(vocab[pad_token]).to(device)\n",
    "            gen_key_padding_mask = gen_genes.eq(vocab[pad_token]).to(device)\n",
    "            _, gen_output = model.transformer_generate(\n",
    "                pcpt_genes=pcpt_genes,\n",
    "                pcpt_values=pcpt_values,\n",
    "                pcpt_key_padding_mask=pcpt_key_padding_mask,\n",
    "                gen_genes=gen_genes,\n",
    "                gen_key_padding_mask=gen_key_padding_mask,\n",
    "            )\n",
    "            select_mask = (gen_genes == query_id_select.unsqueeze(1)).long()\n",
    "            selected_output = gen_output[torch.arange(gen_output.shape[0]), select_mask.argmax(dim=1), :]\n",
    "            selected_output_np = selected_output.detach().cpu().numpy()\n",
    "            gene_embeddings[cell_counter_batch.detach().cpu().numpy(), gene_counter_batch.detach().cpu().numpy(), :] = selected_output_np\n",
    "    \n",
    "    conditions = adata_t.obs['condition'].values\n",
    "    \n",
    "    dict_sum_condition_mean = {}\n",
    "    for c in np.unique(conditions):\n",
    "        dict_sum_condition_mean[c] = gene_embeddings[np.where(conditions == c)[0]].mean(0)\n",
    "    \n",
    "    print(dict_sum_condition_mean)\n",
    "        \n",
    "    celltype_0 = select_gene + '+ctrl'\n",
    "    celltype_1 = 'ctrl'\n",
    "    gene_emb_celltype_0 = np.expand_dims(dict_sum_condition_mean[celltype_0][1:, 1:], 0)\n",
    "    gene_emb_celltype_1 = np.expand_dims(dict_sum_condition_mean[celltype_1][1:, 1:], 0)\n",
    "    gene_dist_dict = {}\n",
    "    for i, g in tqdm(enumerate(genes)):\n",
    "        gene_dist_dict[g] = cosine_distances(gene_emb_celltype_0[:, i, :], gene_emb_celltype_1[:, i, :]).mean()\n",
    "    df_gene_emb_dist = pd.DataFrame.from_dict(gene_dist_dict, orient='index', columns=['cos_dist'])\n",
    "    df_deg = df_gene_emb_dist.sort_values(by='cos_dist', ascending=False)\n",
    "    rank_celltype_0 = np.where(df_deg.index==celltype_0.split('+')[0])[0][0]\n",
    "    print(celltype_0, rank_celltype_0) \n",
    "    np.savez(str(save_dir)+\"mean_gene_emb_{}_{}.npz\".format(select_gene, rank_celltype_0), **dict_sum_condition_mean)\n",
    "    print(f'Saved:\\n{str(save_dir)+\"mean_gene_emb_{}_{}.npz\".format(select_gene, rank_celltype_0)}')\n",
    "    assert(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
