{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abafa220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/chloexq/.local/lib/python3.9/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "#import scvi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "#import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, eval_scib_metrics, load_pretrained\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716574d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchloewxq\u001b[0m (\u001b[33mscformer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/chloexq/scgpt-vevo-attn/notebooks/wandb/run-20250217_111917-sifdo5iu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scformer/scGPT/runs/sifdo5iu' target=\"_blank\">solar-snow-786</a></strong> to <a href='https://wandb.ai/scformer/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scformer/scGPT' target=\"_blank\">https://wandb.ai/scformer/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scformer/scGPT/runs/sifdo5iu' target=\"_blank\">https://wandb.ai/scformer/scGPT/runs/sifdo5iu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'dataset_name': 'fibro', 'do_train': True, 'load_model': '/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model', 'model_name': 'best_model.pt', 'GEPC': True, 'ecs_thres': 0.8, 'dab_weight': 1.0, 'mask_ratio': 0.4, 'epochs': 15, 'n_bins': 51, 'lr': 0.0001, 'batch_size': 64, 'layer_size': 128, 'nlayers': 4, 'nhead': 4, 'dropout': 0.2, 'schedule_ratio': 0.9, 'save_eval_interval': 5, 'log_interval': 100, 'fast_transformer': True, 'pre_norm': False, 'amp': True}\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=42,\n",
    "    dataset_name=\"fibro\", # Dataset name\n",
    "    do_train=True, # Flag to indicate whether to do update model parameters during training\n",
    "    load_model=\"/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model\",\n",
    "    model_name=\"best_model.pt\",\n",
    "    #\"/scratch/ssd004/scratch/chloexq/fibro/dev_fibro-Jun19-18-29\",\n",
    "    #\"/scratch/ssd004/scratch/chloexq/fibro/dev_fibro-Jun23-14-13\", # Path to pre-trained model\n",
    "    GEPC=True,  # Gene expression modelling for cell objective\n",
    "    ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0, # DAR objective weight for batch correction\n",
    "    mask_ratio=0.4, # Default mask ratio\n",
    "    epochs=15, # Default number of epochs for fine-tuning\n",
    "    n_bins=51, # Default number of bins for value binning in data pre-processing\n",
    "    lr=1e-4, # Default learning rate for fine-tuning\n",
    "    batch_size=64, # Default batch size for fine-tuning\n",
    "    layer_size=128,\n",
    "    nlayers=4,\n",
    "    nhead=4, # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2, # Default dropout rate during model fine-tuning\n",
    "    schedule_ratio=0.9,  # Default rate for learning rate decay\n",
    "    save_eval_interval=5, # Default model evaluation interval\n",
    "    log_interval=100, # Default log interval\n",
    "    fast_transformer=True, # Default setting\n",
    "    pre_norm=False, # Default setting\n",
    "    amp=True,  # # Default setting: Automatic Mixed Precision\n",
    ")\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6211854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to /scratch/ssd004/scratch/chloexq/fibro/dev_fibro-Feb17-11-19\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# settings for input and preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = config.n_bins\n",
    "\n",
    "n_hvg = 1200  # number of highly variable genes\n",
    "max_seq_len = n_hvg + 1\n",
    "per_seq_batch_sample = True\n",
    "DSBN = False  # Domain-spec batchnorm\n",
    "explicit_zero_prob = True  # whether explicit bernoulli for zeros\n",
    "\n",
    "dataset_name = config.dataset_name\n",
    "save_dir = Path(f\"/scratch/ssd004/scratch/chloexq/fibro/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325086b",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset\n",
    "\n",
    "####  âœ… Note\n",
    "Perturbation datasets can be found in this path: `/scratch/ssd004/scratch/chloexq/perturb_analysis/{dataset_name}` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8699653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/scratch/ssd004/scratch/chloexq/perturb_analysis\")\n",
    "adata = sc.read(data_dir / \"adamson/perturb_processed.h5ad\")\n",
    "ori_batch_col = \"control\"\n",
    "adata.obs[\"celltype\"] = adata.obs[\"condition\"].astype(\"category\")\n",
    "adata.obs[\"str_batch\"] = adata.obs[\"control\"].astype(str)\n",
    "data_is_raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e74c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 4399/5060 genes in vocabulary of size 60697.\n",
      "Resume model from /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/best_model.pt, the model args will be overriden by the config /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/args.json.\n"
     ]
    }
   ],
   "source": [
    "if config.load_model is not None:\n",
    "    model_dir = Path(config.load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / config.model_name\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    print(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n",
    "    \n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    print(\n",
    "        f\"Resume model from {model_file}, the model args will be overriden by the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "else:\n",
    "    embsize = config.layer_size \n",
    "    nhead = config.nhead\n",
    "    nlayers = config.nlayers  \n",
    "    d_hid = config.layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e69a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align perturbation condition naming\n",
    "gene_names_set = [i + '+ctrl' for i in adata.var.gene_name.values]\n",
    "gene_names_set = gene_names_set + ['ctrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87bc29",
   "metadata": {},
   "source": [
    "####  âœ… Note\n",
    "This experiment is computationally expensive, so we select 1000 cells per perturbation condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1185ae66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMIGO3+ctrl</th>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARHGAP22+ctrl</th>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASCC3+ctrl</th>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHLHE40+ctrl</th>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAD+ctrl</th>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UFM1+ctrl</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRN1+ctrl</th>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YIPF5+ctrl</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF326+ctrl</th>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cell_type  dose_val  control  condition_name  celltype  \\\n",
       "condition                                                               \n",
       "AMIGO3+ctrl          616       616      616             616       616   \n",
       "ARHGAP22+ctrl        406       406      406             406       406   \n",
       "ASCC3+ctrl           524       524      524             524       524   \n",
       "BHLHE40+ctrl         504       504      504             504       504   \n",
       "CAD+ctrl             242       242      242             242       242   \n",
       "...                  ...       ...      ...             ...       ...   \n",
       "UFM1+ctrl            591       591      591             591       591   \n",
       "XRN1+ctrl            621       621      621             621       621   \n",
       "YIPF5+ctrl          1000      1000     1000            1000      1000   \n",
       "ZNF326+ctrl          517       517      517             517       517   \n",
       "ctrl                1000      1000     1000            1000      1000   \n",
       "\n",
       "               str_batch  \n",
       "condition                 \n",
       "AMIGO3+ctrl          616  \n",
       "ARHGAP22+ctrl        406  \n",
       "ASCC3+ctrl           524  \n",
       "BHLHE40+ctrl         504  \n",
       "CAD+ctrl             242  \n",
       "...                  ...  \n",
       "UFM1+ctrl            591  \n",
       "XRN1+ctrl            621  \n",
       "YIPF5+ctrl          1000  \n",
       "ZNF326+ctrl          517  \n",
       "ctrl                1000  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap all conditions to 1000 cells\n",
    "sampled_df = (\n",
    "    adata.obs[adata.obs['condition'].isin(gene_names_set)]\n",
    "    .groupby('condition', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), 1000), random_state=42))\n",
    ")\n",
    "adata = adata[sampled_df.index].copy()\n",
    "adata.obs.groupby('condition').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2e8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 conditions are capped, including ctrl\n",
    "condition_counts = adata.obs.groupby('condition').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926217f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = set(adata.obs.condition.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20cf69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names.remove('ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9982e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene = [i.split('+')[0] for i in list(condition_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2272c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36541c6",
   "metadata": {},
   "source": [
    "####  âœ… Note\n",
    "HVGs selection will filter out some perturbed genes. We manually add them back in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c33ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n"
     ]
    }
   ],
   "source": [
    "# Do filtering\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=3,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    #binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    #result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e45f8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    layer=None,\n",
    "    n_top_genes=1200,\n",
    "    flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    subset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8063a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_counter = 0\n",
    "for g in condition_names_gene:\n",
    "    if not adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'].values[0]:\n",
    "        adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'] = True\n",
    "        add_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8289f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually add conditions: 67, 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Manually add conditions: {}, {}'.format(add_counter, add_counter/len(condition_names_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a03de12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=0,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86235b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs Ã— n_vars = 39847 Ã— 1267\n",
      "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch'\n",
      "    var: 'gene_name', 'id_in_vocab', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n",
      "    obsm: 'bin_edges'\n",
      "    layers: 'X_binned'\n"
     ]
    }
   ],
   "source": [
    "adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ae37c",
   "metadata": {},
   "source": [
    "## Prepare model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ebbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = adata.shape[1] + 1\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24b2aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['batch_id'] = adata.obs['condition'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555624b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_key = \"X_binned\"\n",
    "all_counts = (\n",
    "    adata.layers[input_layer_key].A\n",
    "    if issparse(adata.layers[input_layer_key])\n",
    "    else adata.layers[input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "celltypes_labels = adata.obs[\"celltype\"].tolist()  # make sure count from 0\n",
    "num_types = len(set(celltypes_labels))\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "batch_ids = np.array(batch_ids)\n",
    "\n",
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_celltype_labels,\n",
    "    valid_celltype_labels,\n",
    "    train_batch_labels,\n",
    "    valid_batch_labels,\n",
    ") = train_test_split(\n",
    "    all_counts, celltypes_labels, batch_ids, test_size=0.1, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3663c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bfd1e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3939b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 39847 Ã— 1267\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch', 'batch_id'\n",
       "    var: 'gene_name', 'id_in_vocab', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n",
       "    obsm: 'bin_edges'\n",
       "    layers: 'X_binned'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e4a5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sort_seq_batch=False) -> Tuple[Dict[str, torch.Tensor]]:\n",
    "    masked_values_train = random_mask_value(\n",
    "        tokenized_train[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    masked_values_valid = random_mask_value(\n",
    "        tokenized_valid[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    print(\n",
    "        f\"random masking at epoch {epoch:3d}, ratio of masked values in train: \",\n",
    "        f\"{(masked_values_train == mask_value).sum() / (masked_values_train - pad_value).count_nonzero():.4f}\",\n",
    "    )\n",
    "\n",
    "    input_gene_ids_train, input_gene_ids_valid = (\n",
    "        tokenized_train[\"genes\"],\n",
    "        tokenized_valid[\"genes\"],\n",
    "    )\n",
    "    input_values_train, input_values_valid = masked_values_train, masked_values_valid\n",
    "    target_values_train, target_values_valid = (\n",
    "        tokenized_train[\"values\"],\n",
    "        tokenized_valid[\"values\"],\n",
    "    )\n",
    "\n",
    "    tensor_batch_labels_train = torch.from_numpy(train_batch_labels).long()\n",
    "    tensor_batch_labels_valid = torch.from_numpy(valid_batch_labels).long()\n",
    "\n",
    "    if sort_seq_batch:\n",
    "        train_sort_ids = np.argsort(train_batch_labels)\n",
    "        input_gene_ids_train = input_gene_ids_train[train_sort_ids]\n",
    "        input_values_train = input_values_train[train_sort_ids]\n",
    "        target_values_train = target_values_train[train_sort_ids]\n",
    "        tensor_batch_labels_train = tensor_batch_labels_train[train_sort_ids]\n",
    "\n",
    "        valid_sort_ids = np.argsort(valid_batch_labels)\n",
    "        input_gene_ids_valid = input_gene_ids_valid[valid_sort_ids]\n",
    "        input_values_valid = input_values_valid[valid_sort_ids]\n",
    "        target_values_valid = target_values_valid[valid_sort_ids]\n",
    "        tensor_batch_labels_valid = tensor_batch_labels_valid[valid_sort_ids]\n",
    "\n",
    "    train_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_train,\n",
    "        \"values\": input_values_train,\n",
    "        \"target_values\": target_values_train,\n",
    "        \"batch_labels\": tensor_batch_labels_train,\n",
    "    }\n",
    "    valid_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_valid,\n",
    "        \"values\": input_values_valid,\n",
    "        \"target_values\": target_values_valid,\n",
    "        \"batch_labels\": tensor_batch_labels_valid,\n",
    "    }\n",
    "\n",
    "    return train_data_pt, valid_data_pt\n",
    "\n",
    "\n",
    "# dataset\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "\n",
    "# data_loader\n",
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    if per_seq_batch_sample:\n",
    "        # find the indices of samples in each seq batch\n",
    "        subsets = []\n",
    "        batch_labels_array = data_pt[\"batch_labels\"].numpy()\n",
    "        for batch_label in np.unique(batch_labels_array):\n",
    "            batch_indices = np.where(batch_labels_array == batch_label)[0].tolist()\n",
    "            subsets.append(batch_indices)\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_sampler=SubsetsBatchSampler(\n",
    "                subsets,\n",
    "                batch_size,\n",
    "                intra_subset_shuffle=intra_domain_shuffle,\n",
    "                inter_subset_shuffle=shuffle,\n",
    "                drop_last=drop_last,\n",
    "            ),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return data_loader\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5753701",
   "metadata": {},
   "source": [
    "## Load the pre-trained scGPT model\n",
    "####  âœ… Note\n",
    "Make sure to import from .model instead of .model_pcpt in __ init __.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e346fb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    dropout=config.dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=config.GEPC,\n",
    "    do_dab=False,\n",
    "    use_batch_labels=False,\n",
    "    num_batch_labels=num_batch_types,\n",
    "    domain_spec_batchnorm=DSBN,\n",
    "    n_input_bins=n_input_bins,\n",
    "    ecs_threshold=config.ecs_thres,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=config.fast_transformer,\n",
    "    use_generative_training=True,\n",
    "    pre_norm=config.pre_norm,\n",
    ")\n",
    "if config.load_model is not None:\n",
    "    load_pretrained(model, torch.load(model_file), verbose=False)\n",
    "\n",
    "model.to(device)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dd1c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "adata_t = adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72590980",
   "metadata": {},
   "source": [
    "## Expand cells\n",
    "ðŸ“— Slide deck pages 66-73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52a4ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cell(tokenized_all, key, k, select_gene_id):\n",
    "    # tokenzed_all: gene expression profiles e.g., AMIGO3 and control\n",
    "    # key: key for genes list in tokenized_all\n",
    "    # k: current cell index\n",
    "    # select_gene_id: perturbed gene index\n",
    "    cell_k = tokenized_all[key][k]\n",
    "    # Repeat cell_k n_genes times\n",
    "    # [n_genes, n_genes]\n",
    "    cell_k_expand = cell_k.repeat(n_genes).view(n_genes, n_genes)\n",
    "    # Append a new column of PAD tokens to the end (page 68 in slides)\n",
    "    new_column = torch.full((n_genes, 1), vocab([pad_token])[0])\n",
    "    cell_k_expand = torch.cat((cell_k_expand, new_column), dim=1)\n",
    "    # Create mask (page 69 in slides)\n",
    "    # Set diagonal to be True\n",
    "    mask = torch.eye(n_genes).bool()\n",
    "    new_column_mask = torch.full((n_genes, 1), False)\n",
    "    # [n_genes, n_genes+1], last column is PAD, hence set to be False\n",
    "    mask = torch.cat((mask, new_column_mask), dim=1)\n",
    "    # Set column of perturbed gene to be True\n",
    "    mask[:, select_gene_id] = True\n",
    "    # Set one PAD to be True\n",
    "    mask[select_gene_id, n_genes] = True\n",
    "    mask_select_expand = cell_k_expand[mask]\n",
    "    select_ids_gen = mask_select_expand.view(n_genes, 2)\n",
    "    select_ids_pcpt = cell_k_expand[~mask].view(n_genes, n_genes-1)\n",
    "    return select_ids_gen, select_ids_pcpt\n",
    "\n",
    "from tqdm import tqdm\n",
    "def collate_cell_by_key(tokenized_all, key, select_gene_id):\n",
    "    # tokenzed_all: gene expression profiles e.g., AMIGO3 and control\n",
    "    # key: key for genes list in tokenized_all\n",
    "    # select_gene_id: perturbed gene index\n",
    "    print(key)\n",
    "    select_ids_gen_list = []\n",
    "    select_ids_pcpt_list = []\n",
    "    for k in tqdm(range(n_cells)):\n",
    "        # Iterate through each cell\n",
    "        # Expand each cell to 1268 fakle cells\n",
    "        select_ids_gen, select_ids_pcpt = expand_cell(tokenized_all, key, k, select_gene_id)\n",
    "        select_ids_gen_list.append(select_ids_gen)\n",
    "        select_ids_pcpt_list.append(select_ids_pcpt)\n",
    "    select_ids_gen = torch.cat(select_ids_gen_list, dim=0)\n",
    "    select_ids_pcpt = torch.cat(select_ids_pcpt_list, dim=0)\n",
    "    print(select_ids_gen.shape, select_ids_pcpt.shape)\n",
    "    return select_ids_gen, select_ids_pcpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34c22462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9421cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0418da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_barcode\n",
      "CAGGCCGAGATGAA-2     AMIGO3+ctrl\n",
      "CACACCTGCATCAG-4     AMIGO3+ctrl\n",
      "CCAAGTGAGTATGC-10    AMIGO3+ctrl\n",
      "TGCACGCTACCTTT-3     AMIGO3+ctrl\n",
      "GGAGCCACTGCCCT-2     AMIGO3+ctrl\n",
      "                        ...     \n",
      "CTTGTATGGTATGC-3            ctrl\n",
      "GTGGTAACCTACTT-8            ctrl\n",
      "GCAAACTGATTCCT-1            ctrl\n",
      "TTCTCAGATTCATC-5            ctrl\n",
      "GACCTAGAGGAGTG-1            ctrl\n",
      "Name: condition, Length: 1616, dtype: category\n",
      "Categories (2, object): ['AMIGO3+ctrl', 'ctrl']\n",
      "265\n",
      "torch.Size([1616, 1268]) torch.Size([1616, 1268])\n",
      "genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1616 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "1268\n",
      "torch.Size([1268, 1269])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m n_genes \u001b[38;5;241m=\u001b[39m tokenized_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Expand to N_cells*1268 fake cells\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# select_gene_id = perturbed gene\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m collate_genes_gen, collate_genes_pcpt \u001b[38;5;241m=\u001b[39m \u001b[43mcollate_cell_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselect_gene_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m _, collate_values_pcpt \u001b[38;5;241m=\u001b[39m collate_cell_by_key(tokenized_all, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m, select_gene_id)\n\u001b[1;32m     45\u001b[0m tokenized_all_expand \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes_pcpt\u001b[39m\u001b[38;5;124m'\u001b[39m: collate_genes_pcpt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes_gen\u001b[39m\u001b[38;5;124m'\u001b[39m: collate_genes_gen, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues_pcpt\u001b[39m\u001b[38;5;124m'\u001b[39m: collate_values_pcpt}\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mcollate_cell_by_key\u001b[0;34m(tokenized_all, key, select_gene_id)\u001b[0m\n\u001b[1;32m     39\u001b[0m select_ids_pcpt_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_cells)):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Iterate through each cell\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Expand each cell to 1268 fakle cells\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     select_ids_gen, select_ids_pcpt \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselect_gene_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     select_ids_gen_list\u001b[38;5;241m.\u001b[39mappend(select_ids_gen)\n\u001b[1;32m     45\u001b[0m     select_ids_pcpt_list\u001b[38;5;241m.\u001b[39mappend(select_ids_pcpt)\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mexpand_cell\u001b[0;34m(tokenized_all, key, k, select_gene_id)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_genes)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m mask_select_expand \u001b[38;5;241m=\u001b[39m cell_k_expand[mask]\n\u001b[1;32m     28\u001b[0m select_ids_gen \u001b[38;5;241m=\u001b[39m mask_select_expand\u001b[38;5;241m.\u001b[39mview(n_genes, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "select_gene_list = condition_names_gene\n",
    "\n",
    "for select_gene in select_gene_list:\n",
    "    # Filter on perturbed gene and control gene\n",
    "    adata_t = adata[adata.obs['condition'].isin([select_gene+'+ctrl', 'ctrl'])].copy()\n",
    "    print(adata_t.obs['condition'])\n",
    "    # Bug fix: select_gene_id should have +1\n",
    "    select_gene_id = genes.index(select_gene)+1\n",
    "    print(select_gene_id)\n",
    "    all_counts = (\n",
    "        adata_t.layers[input_layer_key].A\n",
    "        if issparse(adata_t.layers[input_layer_key])\n",
    "        else adata_t.layers[input_layer_key]\n",
    "    )\n",
    "    celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "    batch_ids = np.array(batch_ids)\n",
    "\n",
    "    tokenized_all = tokenize_and_pad_batch(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=True,\n",
    "    )\n",
    "\n",
    "    # tokenized_all output genes and values in format [CLS, G0, G1, G2 ...]\n",
    "    all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "    src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "    # [N_cells, 1268] => 1267+1\n",
    "    print(tokenized_all['genes'].shape, tokenized_all['values'].shape)\n",
    "    n_cells = tokenized_all['genes'].shape[0]\n",
    "    n_genes = tokenized_all['genes'].shape[1]\n",
    "    \n",
    "    # Expand to N_cells*1268 fake cells\n",
    "    # select_gene_id = perturbed gene\n",
    "    collate_genes_gen, collate_genes_pcpt = collate_cell_by_key(tokenized_all, 'genes', select_gene_id)\n",
    "    _, collate_values_pcpt = collate_cell_by_key(tokenized_all, 'values', select_gene_id)\n",
    "    \n",
    "    tokenized_all_expand = {'genes_pcpt': collate_genes_pcpt, 'genes_gen': collate_genes_gen, 'values_pcpt': collate_values_pcpt}\n",
    "    print(tokenized_all_expand)\n",
    "    query_id = tokenized_all['genes'][0].repeat(n_cells)\n",
    "    \n",
    "    cell_counter = torch.arange(0, n_cells)\n",
    "    cell_counter = cell_counter.repeat(n_genes).view(n_genes, n_cells).t().flatten()\n",
    "    gene_counter = torch.arange(0, n_genes).repeat(n_cells)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        TensorDataset(tokenized_all_expand['genes_pcpt'], \n",
    "                      tokenized_all_expand['genes_gen'], \n",
    "                      tokenized_all_expand['values_pcpt'],\n",
    "                      query_id,\n",
    "                      cell_counter,\n",
    "                      gene_counter,\n",
    "                     ), \n",
    "        batch_size=512, \n",
    "        shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    gene_embeddings = np.zeros((n_cells, n_genes, 512))\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=config.amp):\n",
    "        for batch_idx, batch_data in enumerate(tqdm(dataloader)):\n",
    "            pcpt_genes = batch_data[0].to(device)\n",
    "            gen_genes = batch_data[1].to(device)\n",
    "            pcpt_values = batch_data[2].to(device)\n",
    "            query_id_select = batch_data[3].to(device)\n",
    "            cell_counter_batch = batch_data[4].to(device)\n",
    "            gene_counter_batch = batch_data[5].to(device)\n",
    "            pcpt_key_padding_mask = pcpt_genes.eq(vocab[pad_token]).to(device)\n",
    "            gen_key_padding_mask = gen_genes.eq(vocab[pad_token]).to(device)\n",
    "            _, gen_output = model.transformer_generate(\n",
    "                pcpt_genes=pcpt_genes,\n",
    "                pcpt_values=pcpt_values,\n",
    "                pcpt_key_padding_mask=pcpt_key_padding_mask,\n",
    "                gen_genes=gen_genes,\n",
    "                gen_key_padding_mask=gen_key_padding_mask,\n",
    "            )\n",
    "            select_mask = (gen_genes == query_id_select.unsqueeze(1)).long()\n",
    "            selected_output = gen_output[torch.arange(gen_output.shape[0]), select_mask.argmax(dim=1), :]\n",
    "            selected_output_np = selected_output.detach().cpu().numpy()\n",
    "            gene_embeddings[cell_counter_batch.detach().cpu().numpy(), gene_counter_batch.detach().cpu().numpy(), :] = selected_output_np\n",
    "    \n",
    "    conditions = adata_t.obs['condition'].values\n",
    "    \n",
    "    dict_sum_condition_mean = {}\n",
    "    for c in np.unique(conditions):\n",
    "        dict_sum_condition_mean[c] = gene_embeddings[np.where(conditions == c)[0]].mean(0)\n",
    "    \n",
    "    print(dict_sum_condition_mean)\n",
    "        \n",
    "    celltype_0 = select_gene + '+ctrl'\n",
    "    celltype_1 = 'ctrl'\n",
    "    gene_emb_celltype_0 = np.expand_dims(dict_sum_condition_mean[celltype_0][1:, 1:], 0)\n",
    "    gene_emb_celltype_1 = np.expand_dims(dict_sum_condition_mean[celltype_1][1:, 1:], 0)\n",
    "    gene_dist_dict = {}\n",
    "    for i, g in tqdm(enumerate(genes)):\n",
    "        gene_dist_dict[g] = cosine_distances(gene_emb_celltype_0[:, i, :], gene_emb_celltype_1[:, i, :]).mean()\n",
    "    df_gene_emb_dist = pd.DataFrame.from_dict(gene_dist_dict, orient='index', columns=['cos_dist'])\n",
    "    df_deg = df_gene_emb_dist.sort_values(by='cos_dist', ascending=False)\n",
    "    rank_celltype_0 = np.where(df_deg.index==celltype_0.split('+')[0])[0][0]\n",
    "    print(celltype_0, rank_celltype_0) \n",
    "    np.savez('/scratch/hdd001/home/haotian/perturb_data/vevo_adamson_mean_gene_emb/mean_gene_emb_{}_{}.npz'.format(select_gene, rank_celltype_0), **dict_sum_condition_mean)\n",
    "    assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37920905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a428a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42805751",
   "metadata": {},
   "source": [
    "## Example gene - AMIGO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa1d29b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[264]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_gene = 'AMIGO3'\n",
    "select_gene_id = [genes.index(select_gene)]\n",
    "select_gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ca655eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = (\n",
    "    adata_t.layers[input_layer_key].A\n",
    "    if issparse(adata_t.layers[input_layer_key])\n",
    "    else adata_t.layers[input_layer_key]\n",
    ")\n",
    "\n",
    "celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "batch_ids = np.array(batch_ids)\n",
    "\n",
    "tokenized_all = tokenize_and_pad_batch(\n",
    "    all_counts,\n",
    "    gene_ids,\n",
    "    max_len=max_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=True,\n",
    ")\n",
    "all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe1a9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genes': tensor([[60695, 10954, 33817,  ..., 11394, 20695, 12288],\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 12288],\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 12288],\n",
       "         ...,\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 12288],\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 12288],\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 12288]]),\n",
       " 'values': tensor([[ 0.,  0.,  0.,  ...,  0., 39.,  0.],\n",
       "         [ 0., 33.,  0.,  ...,  0., 41.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0., 20.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0., 26., 26.],\n",
       "         [ 0.,  0.,  0.,  ...,  0., 25.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4b929e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3292, 1268]), torch.Size([3292, 1268]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_all['genes'].shape, tokenized_all['values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f859e0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "['AMIGO3', 'ARHGAP22', 'ASCC3', 'BHLHE40', 'CAD'] is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m select_gene_id \u001b[38;5;241m=\u001b[39m \u001b[43mgenes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_gene\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m select_gene_id\n",
      "\u001b[0;31mValueError\u001b[0m: ['AMIGO3', 'ARHGAP22', 'ASCC3', 'BHLHE40', 'CAD'] is not in list"
     ]
    }
   ],
   "source": [
    "select_gene_id = genes.index(select_gene)\n",
    "select_gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83e7a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = tokenized_all['genes'].shape[0]\n",
    "n_genes = tokenized_all['genes'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f59bbc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60694]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "509decd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1616/1616 [00:20<00:00, 80.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2049088, 2]) torch.Size([2049088, 1267])\n",
      "values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1616/1616 [00:15<00:00, 101.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2049088, 2]) torch.Size([2049088, 1267])\n"
     ]
    }
   ],
   "source": [
    "collate_genes_gen, collate_genes_pcpt = collate_cell_by_key(tokenized_all, 'genes')\n",
    "_, collate_values_pcpt = collate_cell_by_key(tokenized_all, 'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "900a570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_all_expand = {'genes_pcpt': collate_genes_pcpt, 'genes_gen': collate_genes_gen, 'values_pcpt': collate_values_pcpt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77307b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genes_pcpt': tensor([[10954, 33817, 33823,  ..., 20695, 12288, 60694],\n",
       "         [60695, 33817, 33823,  ..., 20695, 12288, 60694],\n",
       "         [60695, 10954, 33823,  ..., 20695, 12288, 60694],\n",
       "         ...,\n",
       "         [60695, 10954, 33817,  ..., 20695, 12288, 60694],\n",
       "         [60695, 10954, 33817,  ..., 11394, 12288, 60694],\n",
       "         [60695, 10954, 33817,  ..., 11394, 20695, 60694]]),\n",
       " 'genes_gen': tensor([[60695, 17061],\n",
       "         [10954, 17061],\n",
       "         [33817, 17061],\n",
       "         ...,\n",
       "         [17061, 11394],\n",
       "         [17061, 20695],\n",
       "         [17061, 12288]]),\n",
       " 'values_pcpt': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9000e+01, 0.0000e+00,\n",
       "          6.0694e+04],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9000e+01, 0.0000e+00,\n",
       "          6.0694e+04],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9000e+01, 0.0000e+00,\n",
       "          6.0694e+04],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          6.0694e+04],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          6.0694e+04],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          6.0694e+04]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_all_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44047534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2049088])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_id = tokenized_all['genes'][0].repeat(n_cells)\n",
    "query_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a640996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_counter = torch.arange(0, n_cells)\n",
    "cell_counter = cell_counter.repeat(n_genes).view(n_genes, n_cells).t().flatten()\n",
    "gene_counter = torch.arange(0, n_genes).repeat(n_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c03fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    TensorDataset(tokenized_all_expand['genes_pcpt'], \n",
    "                  tokenized_all_expand['genes_gen'], \n",
    "                  tokenized_all_expand['values_pcpt'],\n",
    "                  query_id,\n",
    "                  cell_counter,\n",
    "                  gene_counter,\n",
    "                 ), \n",
    "    batch_size=256, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bf1f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_embeddings = np.load('/scratch/hdd001/home/haotian/perturb_data/gene_emb_AMIGO3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44e051da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.14471959, -0.31810772, -0.15156181, ...,  0.38157901,\n",
       "          0.18877536,  0.00387936],\n",
       "        [ 0.61960208, -0.11534177, -0.06519999, ...,  0.77028453,\n",
       "          0.33847851, -0.34249339],\n",
       "        [ 0.69855273, -0.27113497, -0.60498726, ...,  0.87949604,\n",
       "          0.19560406,  0.19362614],\n",
       "        ...,\n",
       "        [ 0.57298452, -0.40124443,  0.15548812, ...,  1.01221168,\n",
       "          0.26631504, -0.27922907],\n",
       "        [ 0.53930181, -0.35991946, -0.17062013, ...,  0.83171099,\n",
       "         -0.26467252, -0.49455971],\n",
       "        [ 0.05785051, -0.16414733, -0.59651417, ...,  0.6242736 ,\n",
       "          0.00651832,  0.33623916]],\n",
       "\n",
       "       [[-0.02670202, -0.32364917, -0.17526059, ...,  0.2777673 ,\n",
       "          0.19717763,  0.05834019],\n",
       "        [ 0.50269228, -0.11272967, -0.0869033 , ...,  0.63911295,\n",
       "          0.25286543, -0.34779724],\n",
       "        [ 0.57340115, -0.21534836, -0.64286149, ...,  0.76529098,\n",
       "          0.13185714,  0.21523918],\n",
       "        ...,\n",
       "        [ 0.55179942, -0.46997151,  0.14870609, ...,  0.92276049,\n",
       "          0.16443171, -0.28891164],\n",
       "        [ 0.47073722, -0.42725018, -0.20759058, ...,  0.76225942,\n",
       "         -0.3636758 , -0.50890058],\n",
       "        [-0.09437118, -0.09051374, -0.66618073, ...,  0.54113764,\n",
       "         -0.02722744,  0.39827728]],\n",
       "\n",
       "       [[-0.07373542, -0.35002333, -0.28787684, ...,  0.22357216,\n",
       "          0.11229319, -0.01722815],\n",
       "        [ 0.44229749, -0.15932584, -0.11235867, ...,  0.6476872 ,\n",
       "          0.23764797, -0.41604075],\n",
       "        [ 0.50168121, -0.26173955, -0.71107441, ...,  0.76827627,\n",
       "          0.09225135,  0.11643145],\n",
       "        ...,\n",
       "        [ 0.54053539, -0.50337666,  0.06189798, ...,  0.93836236,\n",
       "          0.16356383, -0.38657477],\n",
       "        [ 0.33594525, -0.32596105, -0.34572199, ...,  0.67369926,\n",
       "         -0.44966426, -0.51936674],\n",
       "        [-0.20445494, -0.0214351 , -0.74537319, ...,  0.49609551,\n",
       "         -0.11788296,  0.33130762]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.08792911, -0.31160092, -0.13867739, ...,  0.3197324 ,\n",
       "          0.05587726,  0.13091244],\n",
       "        [ 0.57864237, -0.07627635, -0.07880759, ...,  0.70929587,\n",
       "          0.19098718, -0.25121287],\n",
       "        [ 0.67232805, -0.30058709, -0.51235032, ...,  0.81665319,\n",
       "          0.0938796 ,  0.27015164],\n",
       "        ...,\n",
       "        [ 0.55715787, -0.31814837,  0.1493129 , ...,  0.95214903,\n",
       "          0.15047407, -0.17352933],\n",
       "        [ 0.53814638, -0.32038373, -0.20799714, ...,  0.78044754,\n",
       "         -0.30884489, -0.41001341],\n",
       "        [ 0.04344844, -0.10425801, -0.64734918, ...,  0.55813771,\n",
       "         -0.02691424,  0.52458626]],\n",
       "\n",
       "       [[-0.1268613 , -0.23660006, -0.12204958, ...,  0.16328384,\n",
       "          0.12564835,  0.01731646],\n",
       "        [ 0.44924194,  0.05238144, -0.01058974, ...,  0.5767079 ,\n",
       "          0.20202826, -0.38118762],\n",
       "        [ 0.4879654 , -0.05989236, -0.61744487, ...,  0.65734541,\n",
       "          0.14671677,  0.17587335],\n",
       "        ...,\n",
       "        [ 0.44584432, -0.3398003 ,  0.21397758, ...,  0.87295395,\n",
       "          0.06856489, -0.29332769],\n",
       "        [ 0.38249618, -0.32195219, -0.1611916 , ...,  0.71475291,\n",
       "         -0.34578818, -0.54909873],\n",
       "        [-0.12734534,  0.00843148, -0.61604691, ...,  0.43478203,\n",
       "         -0.01337181,  0.41959098]],\n",
       "\n",
       "       [[ 0.20357546, -0.25658658, -0.14910395, ...,  0.36315578,\n",
       "          0.2810443 ,  0.04851099],\n",
       "        [ 0.68327653, -0.01571544, -0.13211837, ...,  0.73142976,\n",
       "          0.44436216, -0.3128919 ],\n",
       "        [ 0.75419724, -0.09104688, -0.65933222, ...,  0.83641207,\n",
       "          0.33832443,  0.18363297],\n",
       "        ...,\n",
       "        [ 0.62686801, -0.33576235,  0.10629599, ...,  0.93279797,\n",
       "          0.32243389, -0.2046167 ],\n",
       "        [ 0.60956174, -0.28970569, -0.1979533 , ...,  0.81330055,\n",
       "         -0.19049928, -0.48398283],\n",
       "        [ 0.19084898, -0.15669119, -0.58744192, ...,  0.57324755,\n",
       "          0.19346243,  0.3511399 ]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2acd0f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1616, 1268, 512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7027292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 1616 Ã— 1267\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch', 'n_counts', 'batch_id'\n",
       "    var: 'gene_name', 'id_in_vocab', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n",
       "    obsm: 'bin_edges'\n",
       "    layers: 'X_binned'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8da2e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMIGO3+ctrl', 'AMIGO3+ctrl', 'AMIGO3+ctrl', 'AMIGO3+ctrl', 'AMIGO3+ctrl', ..., 'ctrl', 'ctrl', 'ctrl', 'ctrl', 'ctrl']\n",
       "Length: 1616\n",
       "Categories (2, object): ['AMIGO3+ctrl', 'ctrl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = adata_t.obs['condition'].values\n",
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2913e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sum_condition_mean = {}\n",
    "for c in np.unique(conditions):\n",
    "    dict_sum_condition_mean[c] = gene_embeddings[np.where(conditions == c)[0]].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dea2c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMIGO3+ctrl': array([[ 0.02896031, -0.30605496, -0.18769101, ...,  0.31369529,\n",
       "          0.18078589,  0.01247744],\n",
       "        [ 0.53777679, -0.08083235, -0.09220441, ...,  0.7052932 ,\n",
       "          0.30027999, -0.3661572 ],\n",
       "        [ 0.61212808, -0.18003001, -0.64855161, ...,  0.81548358,\n",
       "          0.16254684,  0.16346903],\n",
       "        ...,\n",
       "        [ 0.55028727, -0.41949252,  0.12546903, ...,  0.95711756,\n",
       "          0.22197948, -0.30449767],\n",
       "        [ 0.47133369, -0.32766302, -0.2268176 , ...,  0.76627743,\n",
       "         -0.30820553, -0.49919339],\n",
       "        [-0.02416596, -0.08885051, -0.64301324, ...,  0.56321243,\n",
       "          0.01604781,  0.35337052]]),\n",
       " 'ctrl': array([[ 0.03563262, -0.31076524, -0.1945659 , ...,  0.3190965 ,\n",
       "          0.19469241,  0.03929696],\n",
       "        [ 0.55548337, -0.08925866, -0.10811319, ...,  0.70242681,\n",
       "          0.31922594, -0.3347161 ],\n",
       "        [ 0.60411533, -0.15919195, -0.6666798 , ...,  0.81715135,\n",
       "          0.17643361,  0.18269647],\n",
       "        ...,\n",
       "        [ 0.55992617, -0.4317813 ,  0.11238452, ...,  0.95341574,\n",
       "          0.22896854, -0.28344037],\n",
       "        [ 0.4806865 , -0.33483022, -0.22218429, ...,  0.76598572,\n",
       "         -0.31700926, -0.48346073],\n",
       "        [-0.02540768, -0.09320555, -0.64010307, ...,  0.56980771,\n",
       "          0.02934412,  0.36821847]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sum_condition_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ccf8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1267it [00:00, 4388.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMIGO3+ctrl 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "celltype_0 = select_gene + '+ctrl'\n",
    "celltype_1 = 'ctrl'\n",
    "gene_emb_celltype_0 = np.expand_dims(dict_sum_condition_mean[celltype_0][1:, 1:], 0)\n",
    "gene_emb_celltype_1 = np.expand_dims(dict_sum_condition_mean[celltype_1][1:, 1:], 0)\n",
    "gene_dist_dict = {}\n",
    "for i, g in tqdm(enumerate(genes)):\n",
    "    gene_dist_dict[g] = cosine_distances(gene_emb_celltype_0[:, i, :], gene_emb_celltype_1[:, i, :]).mean()\n",
    "df_gene_emb_dist = pd.DataFrame.from_dict(gene_dist_dict, orient='index', columns=['cos_dist'])\n",
    "df_deg = df_gene_emb_dist.sort_values(by='cos_dist', ascending=False)\n",
    "rank_celltype_0 = np.where(df_deg.index==celltype_0.split('+')[0])[0][0]\n",
    "print(celltype_0, rank_celltype_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18e76766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMIGO3'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10612129",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/scratch/hdd001/home/haotian/perturb_data/vevo_adamson_mean_gene_emb/mean_gene_emb_{}.npz'.format(select_gene), **dict_sum_condition_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca8d1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('/scratch/hdd001/home/haotian/perturb_data/mean_gene_emb_{}.npz'.format(select_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3e0d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02896031, -0.30605496, -0.18769101, ...,  0.31369529,\n",
       "         0.18078589,  0.01247744],\n",
       "       [ 0.53777679, -0.08083235, -0.09220441, ...,  0.7052932 ,\n",
       "         0.30027999, -0.3661572 ],\n",
       "       [ 0.61212808, -0.18003001, -0.64855161, ...,  0.81548358,\n",
       "         0.16254684,  0.16346903],\n",
       "       ...,\n",
       "       [ 0.55028727, -0.41949252,  0.12546903, ...,  0.95711756,\n",
       "         0.22197948, -0.30449767],\n",
       "       [ 0.47133369, -0.32766302, -0.2268176 , ...,  0.76627743,\n",
       "        -0.30820553, -0.49919339],\n",
       "       [-0.02416596, -0.08885051, -0.64301324, ...,  0.56321243,\n",
       "         0.01604781,  0.35337052]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['AMIGO3+ctrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03eaec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "/scratch/hdd001/home/haotian/perturb_data/gene_emb_AMIGO3.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c3b9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec5ecb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1267it [00:00, 3860.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMIGO3+ctrl 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perturb_conditions = ['AMIGO3+ctrl']\n",
    "\n",
    "rank_list = []\n",
    "for i, c in enumerate(perturb_conditions):\n",
    "    celltype_0 = c\n",
    "    celltype_1 = 'ctrl'\n",
    "    gene_emb_celltype_0 = np.expand_dims(dict_sum_condition_mean[celltype_0][1:, 1:], 0)\n",
    "    gene_emb_celltype_1 = np.expand_dims(dict_sum_condition_mean[celltype_1][1:, 1:], 0)\n",
    "    gene_dist_dict = {}\n",
    "    for i, g in tqdm(enumerate(genes)):\n",
    "        gene_dist_dict[g] = cosine_distances(gene_emb_celltype_0[:, i, :], gene_emb_celltype_1[:, i, :]).mean()\n",
    "    df_gene_emb_dist = pd.DataFrame.from_dict(gene_dist_dict, orient='index', columns=['cos_dist'])\n",
    "    df_deg = df_gene_emb_dist.sort_values(by='cos_dist', ascending=False)\n",
    "    print(c, np.where(df_deg.index==c.split('+')[0])[0][0])\n",
    "    rank_list.append(np.where(df_deg.index==c.split('+')[0])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b4325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7d4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cfa6cbaa58e691e8179ea665b67993ad0b84c3c88be4eb7c38e0ba49c71dc67e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
